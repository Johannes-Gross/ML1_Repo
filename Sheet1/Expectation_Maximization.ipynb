{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture"
   ]
  },
  {
   "source": [
    "<h1>Estimating Parameters</h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define means and covariances of the three classes\n",
    "mean1 = [1,1]\n",
    "mean2 = [3,3]\n",
    "mean3 = [2,6]\n",
    "mean = [mean1,mean2, mean3]         #used for error calculation later\n",
    "cov1 = 0.1*np.identity(2)\n",
    "cov2 = 0.2*np.identity(2)\n",
    "cov3 = 0.3*np.identity(2)\n",
    "cov = [0.1, 0.2, 0.3]\n",
    "weights = [0.4, 0.4, 0.2]           #used for error calculation later\n",
    "n_samples = 600\n",
    "\n",
    "#Generate the training data\n",
    "Train1 = np.random.multivariate_normal(mean1,cov1,int(n_samples*0.4))\n",
    "Train2 = np.random.multivariate_normal(mean2,cov2,int(n_samples*0.4))\n",
    "Train3 = np.random.multivariate_normal(mean3,cov3,int(n_samples*0.2))\n",
    "Train = np.concatenate((Train1,Train2,Train3), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use EM algorithm to determine the parameters of the gaussian mixture distribution generated above\n",
    "gmm = mixture.GaussianMixture(n_components=3, covariance_type='spherical',random_state=5)\n",
    "gmm.fit(Train)\n",
    "\n",
    "#plot the data and the estimates for the means\n",
    "plt.scatter(Train[:,0], Train[:,1], label='samples')\n",
    "plt.scatter(gmm.means_[:,0], gmm.means_[:,1], label='mean_est')\n",
    "plt.title('Samples and EM estimates')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#calculate and print the errors for the different parameters in each class\n",
    "for k in [0,1,2]:\n",
    "    weight_error = abs(weights[k] - gmm.weights_[k])\n",
    "    mean_error = np.linalg.norm(mean[k] - gmm.means_[k])                            #error in l2 norm                      \n",
    "    covariance_error = abs(cov[k] - gmm.covariances_[k])                            \n",
    "\n",
    "    print('\\nResults for class ' + str(k+1) + ':')\n",
    "    print('weight_error = ' + str(weight_error))\n",
    "    print('mean_error = ' + str(mean_error))\n",
    "    print('covariance_error = ' + str(covariance_error))\n",
    "\n"
   ]
  },
  {
   "source": [
    "<h1>Varying Initial Parameters</h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the initial parameters of the two cases\n",
    "K = [3,2]\n",
    "weights_init = [[0.34, 0.33, 0.33], [0.5, 0.5]]\n",
    "means_init = [[[0,2], [5,2], [5,5]], [[1.6,1.4], [1.4,1.6]]]\n",
    "precision_init = [[6.66, 3.70, 2.50], [5, 2.5]]\n",
    "titles = ['init_params set 1', 'init_params set 2']\n",
    "\n",
    "for i in [0,1]:\n",
    "    gmm = mixture.GaussianMixture(n_components=K[i], covariance_type='spherical', weights_init=weights_init[i], means_init=means_init[i], precisions_init=precision_init[i] ,random_state=50)\n",
    "    gmm.fit(Train)\n",
    "\n",
    "    tmp = np.array(means_init[i])   #constructing an array from the list, to plot it more easily\n",
    "\n",
    "    #plot the samples and the estimated means for each set\n",
    "    plt.scatter(Train[:,0], Train[:,1], label='samples')\n",
    "    plt.scatter(gmm.means_[:,0], gmm.means_[:,1], label='mean_est')\n",
    "    plt.scatter(tmp[:,0], tmp[:,1], label='mean_init')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "    #print all the estimated parameters\n",
    "    print(\"weights:\")\n",
    "    print(gmm.weights_)\n",
    "    print(\"means:\")\n",
    "    print(gmm.means_)\n",
    "    print(\"covariances:\")\n",
    "    print(gmm.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}