{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining means and covariances for the distributions\n",
    "mean1 = [0,0]\n",
    "mean2 = [10,0]\n",
    "mean3 = [0,6]\n",
    "mean4 = [9,8]\n",
    "means = np.array([mean1, mean2, mean3, mean4])      #needed for the plots later\n",
    "cov1 = np.identity(2)\n",
    "cov2 = [[1,0.2],[0.2,1.5]]\n",
    "cov3 = [[1,0.4],[0.4,1.1]]\n",
    "cov4 = [[0.3,0.2],[0.2,0.5]]\n",
    "n_samples = 1000\n",
    "\n",
    "#creating the data set Train to which kmeans will be fitted later\n",
    "Train1 = np.random.multivariate_normal(mean1,cov1,int(n_samples*0.25))\n",
    "Train2 = np.random.multivariate_normal(mean2,cov2,int(n_samples*0.25))\n",
    "Train3 = np.random.multivariate_normal(mean3,cov3,int(n_samples*0.25))\n",
    "Train4 = np.random.multivariate_normal(mean4,cov4,int(n_samples*0.25))\n",
    "Train = np.concatenate((Train1,Train2,Train3,Train4), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running kmeans for different numbers of initialized classes\n",
    "C = [4,3,5]\n",
    "for c in C:\n",
    "    kmeans = KMeans(n_clusters=c, init='random', algorithm='full', n_init=1, random_state=50)\n",
    "    kmeans.fit(Train)\n",
    "\n",
    "    #plotting the data and the results\n",
    "    plt.scatter(Train[:,0], Train[:,1], label='samples')\n",
    "    plt.scatter(means[:,0], means[:,1], label='means')\n",
    "    plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], label='mean_est')\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title('Number of initialized classes = ' + str(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running kmeans for two additional initializations  \n",
    "means_init1 = np.array([[-2,-2], [-2.1,-2.1], [-2,-2.2], [-2.1,-2.2]])\n",
    "means_init2 = np.array([[np.random.randint(-5,15),np.random.randint(-4,11)], [np.random.randint(-5,15),np.random.randint(-4,11)], [np.random.randint(-5,15),np.random.randint(-4,11)], [30,30]]) #x- and y-value are randomly chosen within the range these values lie in the Train data set\n",
    "means_init = [means_init1, means_init2]\n",
    "titles = ['Means initialized', '3 means random, one is [30,30]']\n",
    "\n",
    "for i in range(len(means_init)):\n",
    "    kmeans = KMeans(n_clusters=4, init=means_init[i], algorithm='full', random_state=1)\n",
    "    kmeans.fit(Train)\n",
    "\n",
    "    plt.scatter(Train[:,0], Train[:,1], label='samples')\n",
    "    plt.scatter(means[:,0], means[:,1], label='means')\n",
    "    plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], label='mean_est')\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title(titles[i])\n",
    "    plt.show()"
   ]
  }
 ]
}